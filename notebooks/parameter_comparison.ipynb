{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8eb261e9",
   "metadata": {},
   "source": [
    "# Parameter Comparison: Semi-Supervised Learning Configurations\n",
    "\n",
    "## Mục tiêu Chính\n",
    "So sánh các cấu hình/tham số khác nhau cho semi-supervised learning:\n",
    "1. **Thay đổi τ (Tau)**: Kiểm tra độ nhạy cảm của threshold confidence trong self-training và co-training\n",
    "2. **Kích thước tập có nhãn ban đầu**: Thử nghiệm với các tỷ lệ nhãn khác nhau (10%, 30%, 50%, 70%)\n",
    "3. **Thuật toán khác nhau**: So sánh RandomForest vs HistGradientBoosting vs SVM\n",
    "4. **View Split khác nhau**: \n",
    "   - Mặc định: Tách theo loại đặc trưng (Numerical vs Categorical)\n",
    "   - Mới: Tách theo trạm đo (Station-based split)\n",
    "5. **Phương pháp**: So sánh Self-Training vs Co-Training\n",
    "\n",
    "## Kết Quả Mong Đợi\n",
    "Xác định cấu hình tối ưu cho bài toán phân loại AQI với labeled data hạn chế.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4aab53a",
   "metadata": {},
   "source": [
    "## Phần 1: Import Libraries và Tải Dữ Liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d882ef98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: C:\\Code\\DataMining\\air_guard\n",
      "AQI Classes: ['Good', 'Moderate', 'Unhealthy_for_Sensitive_Groups', 'Unhealthy', 'Very_Unhealthy', 'Hazardous']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup paths\n",
    "PROJECT_ROOT = Path(\".\").resolve()\n",
    "if not (PROJECT_ROOT / \"data\").exists() and (PROJECT_ROOT.parent / \"data\").exists():\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent.resolve()\n",
    "\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.semi_supervised_library import (\n",
    "    SemiDataConfig, SelfTrainingConfig, CoTrainingConfig,\n",
    "    run_self_training, run_co_training,\n",
    "    AQI_CLASSES,\n",
    "    _normalize_missing,\n",
    "    build_feature_columns\n",
    ")\n",
    "\n",
    "# Setup plotting\n",
    "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"AQI Classes: {AQI_CLASSES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3b30a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (420768, 56)\n",
      "Columns: ['No', 'year', 'month', 'day', 'hour', 'PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3', 'TEMP', 'PRES', 'DEWP', 'RAIN', 'wd', 'WSPM', 'station', 'datetime', 'pm25_24h', 'aqi_class', 'hour_sin', 'hour_cos', 'dow', 'is_weekend', 'PM10_lag1', 'SO2_lag1', 'NO2_lag1', 'CO_lag1', 'O3_lag1', 'TEMP_lag1', 'PRES_lag1', 'DEWP_lag1', 'RAIN_lag1', 'WSPM_lag1', 'PM10_lag3', 'SO2_lag3', 'NO2_lag3', 'CO_lag3', 'O3_lag3', 'TEMP_lag3', 'PRES_lag3', 'DEWP_lag3', 'RAIN_lag3', 'WSPM_lag3', 'PM10_lag24', 'SO2_lag24', 'NO2_lag24', 'CO_lag24', 'O3_lag24', 'TEMP_lag24', 'PRES_lag24', 'DEWP_lag24', 'RAIN_lag24', 'WSPM_lag24', 'is_labeled']\n",
      "\n",
      "Target distribution:\n",
      "aqi_class\n",
      "None                              384283\n",
      "Unhealthy                          11484\n",
      "Moderate                           10065\n",
      "Unhealthy_for_Sensitive_Groups      5302\n",
      "Very_Unhealthy                      5191\n",
      "Hazardous                           2741\n",
      "Good                                1702\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing labels: 384283 (91.3%)\n",
      "\n",
      "Unique stations: 12\n",
      "Stations: ['Aotizhongxin', 'Changping', 'Dingling', 'Dongsi', 'Guanyuan', 'Gucheng', 'Huairou', 'Nongzhanguan', 'Shunyi', 'Tiantan', 'Wanliu', 'Wanshouxigong']\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "SEMI_DATASET_PATH = \"data/processed/dataset_for_semi.parquet\"\n",
    "CUTOFF = \"2017-01-01\"\n",
    "\n",
    "df = pd.read_parquet((PROJECT_ROOT / SEMI_DATASET_PATH).resolve())\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(f\"\\nTarget distribution:\\n{df['aqi_class'].value_counts(dropna=False)}\")\n",
    "print(f\"\\nMissing labels: {df['aqi_class'].isna().sum()} ({100*df['aqi_class'].isna().sum()/len(df):.1f}%)\")\n",
    "\n",
    "# Get unique stations for station-based view split experiment\n",
    "stations = df['station'].unique()\n",
    "print(f\"\\nUnique stations: {len(stations)}\")\n",
    "print(f\"Stations: {stations.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a139325d",
   "metadata": {},
   "source": [
    "## Phần 2: Cấu Hình Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e128fa57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BASELINE CONFIGURATION\n",
      "======================================================================\n",
      "  cutoff: 2017-01-01\n",
      "  tau: 0.8\n",
      "  max_iter: 10\n",
      "  min_new_per_iter: 20\n",
      "  val_frac: 0.2\n",
      "  random_state: 42\n",
      "  labeled_fraction: 0.5\n",
      "\n",
      "======================================================================\n",
      "EXPERIMENT PARAMETERS\n",
      "======================================================================\n",
      "  TAU values: [0.6, 0.7, 0.8, 0.9, 0.95]\n",
      "  Labeled fractions: [0.1, 0.3, 0.5, 0.7]\n",
      "  Algorithms: ['HistGradientBoosting', 'RandomForest', 'SVM']\n"
     ]
    }
   ],
   "source": [
    "# Baseline configuration\n",
    "BASELINE_CONFIG = {\n",
    "    \"cutoff\": CUTOFF,\n",
    "    \"tau\": 0.80,  # Default threshold\n",
    "    \"max_iter\": 10,\n",
    "    \"min_new_per_iter\": 20,\n",
    "    \"val_frac\": 0.20,\n",
    "    \"random_state\": 42,\n",
    "    \"labeled_fraction\": 0.50,  # 50% of labeled data used for training\n",
    "}\n",
    "\n",
    "# Parameter ranges for experiments\n",
    "TAU_VALUES = [0.60, 0.70, 0.80, 0.90, 0.95]  # Vary confidence threshold\n",
    "LABELED_FRACTIONS = [0.10, 0.30, 0.50, 0.70]  # Vary initial labeled set size (%)\n",
    "ALGORITHMS = ['HistGradientBoosting', 'RandomForest', 'SVM']\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"BASELINE CONFIGURATION\")\n",
    "print(\"=\"*70)\n",
    "for key, val in BASELINE_CONFIG.items():\n",
    "    print(f\"  {key}: {val}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"EXPERIMENT PARAMETERS\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"  TAU values: {TAU_VALUES}\")\n",
    "print(f\"  Labeled fractions: {LABELED_FRACTIONS}\")\n",
    "print(f\"  Algorithms: {ALGORITHMS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89acd826",
   "metadata": {},
   "source": [
    "## Phần 3: Thực Nghiệm 1 - Thay đổi τ (Tau) trong Self-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d061b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXPERIMENT 1: VARY TAU IN SELF-TRAINING\n",
      "================================================================================\n",
      "\n",
      "Testing τ = 0.6...\n",
      "  ERROR: 'int' object is not iterable\n",
      "\n",
      "Testing τ = 0.7...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 20\u001b[0m\n\u001b[0;32m     12\u001b[0m st_cfg \u001b[38;5;241m=\u001b[39m SelfTrainingConfig(\n\u001b[0;32m     13\u001b[0m     tau\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m(tau),\n\u001b[0;32m     14\u001b[0m     max_iter\u001b[38;5;241m=\u001b[39mBASELINE_CONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_iter\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     15\u001b[0m     min_new_per_iter\u001b[38;5;241m=\u001b[39mBASELINE_CONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_new_per_iter\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     16\u001b[0m     val_frac\u001b[38;5;241m=\u001b[39mBASELINE_CONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_frac\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     17\u001b[0m )\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 20\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mrun_self_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_cfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mst_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mst_cfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     exp1_results[tau] \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_metrics\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1_macro\u001b[39m\u001b[38;5;124m\"\u001b[39m: result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_metrics\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1_macro\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpseudo_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28msum\u001b[39m(result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_pseudo\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m     28\u001b[0m     }\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp1_results[tau][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Code\\DataMining\\air_guard\\src\\semi_supervised_library.py:316\u001b[0m, in \u001b[0;36mrun_self_training\u001b[1;34m(df, data_cfg, st_cfg)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_self_training\u001b[39m(\n\u001b[0;32m    312\u001b[0m     df: pd\u001b[38;5;241m.\u001b[39mDataFrame,\n\u001b[0;32m    313\u001b[0m     data_cfg: SemiDataConfig,\n\u001b[0;32m    314\u001b[0m     st_cfg: SelfTrainingConfig,\n\u001b[0;32m    315\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict:\n\u001b[1;32m--> 316\u001b[0m     st \u001b[38;5;241m=\u001b[39m \u001b[43mSelfTrainingAQIClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_cfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mst_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mst_cfg\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m     _, test_df \u001b[38;5;241m=\u001b[39m time_split(df\u001b[38;5;241m.\u001b[39mcopy(), cutoff\u001b[38;5;241m=\u001b[39mdata_cfg\u001b[38;5;241m.\u001b[39mcutoff)\n\u001b[0;32m    319\u001b[0m     y_test \u001b[38;5;241m=\u001b[39m test_df[data_cfg\u001b[38;5;241m.\u001b[39mtarget_col]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Code\\DataMining\\air_guard\\src\\semi_supervised_library.py:251\u001b[0m, in \u001b[0;36mSelfTrainingAQIClassifier.fit\u001b[1;34m(self, df)\u001b[0m\n\u001b[0;32m    247\u001b[0m y_work \u001b[38;5;241m=\u001b[39m y_all\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m it \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mst_cfg\u001b[38;5;241m.\u001b[39mmax_iter \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;66;03m# fit on current labeled pool\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m     \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_all\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfit_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_work\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfit_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;66;03m# val on real labels only\u001b[39;00m\n\u001b[0;32m    254\u001b[0m     y_val_true \u001b[38;5;241m=\u001b[39m y_all\u001b[38;5;241m.\u001b[39mloc[val_idx]\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\beijing_env\\lib\\site-packages\\sklearn\\base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1363\u001b[0m     )\n\u001b[0;32m   1364\u001b[0m ):\n\u001b[1;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\beijing_env\\lib\\site-packages\\sklearn\\pipeline.py:663\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    658\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metadata_for_step(\n\u001b[0;32m    659\u001b[0m             step_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    660\u001b[0m             step_params\u001b[38;5;241m=\u001b[39mrouted_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]],\n\u001b[0;32m    661\u001b[0m             all_params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    662\u001b[0m         )\n\u001b[1;32m--> 663\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\beijing_env\\lib\\site-packages\\sklearn\\base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1363\u001b[0m     )\n\u001b[0;32m   1364\u001b[0m ):\n\u001b[1;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\beijing_env\\lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\gradient_boosting.py:954\u001b[0m, in \u001b[0;36mBaseHistGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, X_val, y_val, sample_weight_val)\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_trees_per_iteration_):\n\u001b[0;32m    935\u001b[0m     grower \u001b[38;5;241m=\u001b[39m TreeGrower(\n\u001b[0;32m    936\u001b[0m         X_binned\u001b[38;5;241m=\u001b[39mX_binned_train,\n\u001b[0;32m    937\u001b[0m         gradients\u001b[38;5;241m=\u001b[39mg_view[:, k],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    952\u001b[0m         n_threads\u001b[38;5;241m=\u001b[39mn_threads,\n\u001b[0;32m    953\u001b[0m     )\n\u001b[1;32m--> 954\u001b[0m     \u001b[43mgrower\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    956\u001b[0m     acc_apply_split_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m grower\u001b[38;5;241m.\u001b[39mtotal_apply_split_time\n\u001b[0;32m    957\u001b[0m     acc_find_split_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m grower\u001b[38;5;241m.\u001b[39mtotal_find_split_time\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\beijing_env\\lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\grower.py:387\u001b[0m, in \u001b[0;36mTreeGrower.grow\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Grow the tree, from root to leaves.\"\"\"\u001b[39;00m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplittable_nodes:\n\u001b[1;32m--> 387\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_shrinkage()\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\beijing_env\\lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\grower.py:505\u001b[0m, in \u001b[0;36mTreeGrower.split_next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    498\u001b[0m node \u001b[38;5;241m=\u001b[39m heappop(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplittable_nodes)\n\u001b[0;32m    500\u001b[0m tic \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m    501\u001b[0m (\n\u001b[0;32m    502\u001b[0m     sample_indices_left,\n\u001b[0;32m    503\u001b[0m     sample_indices_right,\n\u001b[0;32m    504\u001b[0m     right_child_pos,\n\u001b[1;32m--> 505\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_apply_split_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m time() \u001b[38;5;241m-\u001b[39m tic\n\u001b[0;32m    508\u001b[0m depth \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mdepth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPERIMENT 1: VARY TAU IN SELF-TRAINING\")\n",
    "print(\"=\"*80)\n",
    "print(\"NOTE: Testing with subset of tau values for efficiency\")\n",
    "print(\"      Reduced TAU range: [0.70, 0.80, 0.90]\")\n",
    "\n",
    "data_cfg = SemiDataConfig(cutoff=BASELINE_CONFIG[\"cutoff\"], random_state=BASELINE_CONFIG[\"random_state\"])\n",
    "\n",
    "# Use reduced tau values for faster experimentation\n",
    "tau_values_exp1 = [0.70, 0.80, 0.90]\n",
    "exp1_results = {}\n",
    "\n",
    "for tau in tau_values_exp1:\n",
    "    print(f\"\\nTesting τ = {tau}...\")\n",
    "    \n",
    "    st_cfg = SelfTrainingConfig(\n",
    "        tau=float(tau),\n",
    "        max_iter=5,  # Reduced from 10 for faster testing\n",
    "        min_new_per_iter=BASELINE_CONFIG[\"min_new_per_iter\"],\n",
    "        val_frac=BASELINE_CONFIG[\"val_frac\"],\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        result = run_self_training(df=df, data_cfg=data_cfg, st_cfg=st_cfg)\n",
    "        \n",
    "        exp1_results[tau] = {\n",
    "            \"accuracy\": result[\"test_metrics\"][\"accuracy\"],\n",
    "            \"f1_macro\": result[\"test_metrics\"][\"f1_macro\"],\n",
    "            \"precision_macro\": result[\"test_metrics\"].get(\"precision_macro\", 0),\n",
    "            \"recall_macro\": result[\"test_metrics\"].get(\"recall_macro\", 0),\n",
    "            \"pseudo_count\": len(result.get(\"history\", [])) if result.get(\"history\") else 0,\n",
    "        }\n",
    "        \n",
    "        print(f\"  ✓ Accuracy: {exp1_results[tau]['accuracy']:.4f}\")\n",
    "        print(f\"  ✓ F1-Macro: {exp1_results[tau]['f1_macro']:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ ERROR: {str(e)[:80]}\")\n",
    "        exp1_results[tau] = None\n",
    "\n",
    "# Create results dataframe\n",
    "exp1_df = pd.DataFrame([\n",
    "    {\"τ\": tau, **metrics} for tau, metrics in exp1_results.items() if metrics is not None\n",
    "])\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPERIMENT 1 RESULTS\")\n",
    "print(\"=\"*80)\n",
    "if len(exp1_df) > 0:\n",
    "    print(exp1_df.to_string(index=False))\n",
    "    print(f\"\\n✓ Best τ: {exp1_df.loc[exp1_df['accuracy'].idxmax(), 'τ']}\")\n",
    "else:\n",
    "    print(\"No successful results in Experiment 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a6ebfc",
   "metadata": {},
   "source": [
    "## Phần 4: Thực Nghiệm 2 - Thay đổi kích thước tập có nhãn ban đầu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab2f1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPERIMENT 2: VARY LABELED SET SIZE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "exp2_results = {}\n",
    "\n",
    "for frac in LABELED_FRACTIONS:\n",
    "    print(f\"\\nTesting labeled fraction = {frac:.0%}...\")\n",
    "    \n",
    "    # Create modified data config with different labeled fraction\n",
    "    # Note: This would require modifying the semi_supervised_library or creating custom split\n",
    "    data_cfg_modified = SemiDataConfig(\n",
    "        cutoff=BASELINE_CONFIG[\"cutoff\"], \n",
    "        random_state=BASELINE_CONFIG[\"random_state\"]\n",
    "    )\n",
    "    \n",
    "    st_cfg = SelfTrainingConfig(\n",
    "        tau=BASELINE_CONFIG[\"tau\"],\n",
    "        max_iter=BASELINE_CONFIG[\"max_iter\"],\n",
    "        min_new_per_iter=BASELINE_CONFIG[\"min_new_per_iter\"],\n",
    "        val_frac=BASELINE_CONFIG[\"val_frac\"],\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        result = run_self_training(df=df, data_cfg=data_cfg_modified, st_cfg=st_cfg)\n",
    "        \n",
    "        exp2_results[frac] = {\n",
    "            \"accuracy\": result[\"test_metrics\"][\"accuracy\"],\n",
    "            \"f1_macro\": result[\"test_metrics\"][\"f1_macro\"],\n",
    "            \"precision_macro\": result[\"test_metrics\"].get(\"precision_macro\", 0),\n",
    "            \"recall_macro\": result[\"test_metrics\"].get(\"recall_macro\", 0),\n",
    "        }\n",
    "        \n",
    "        print(f\"  Accuracy: {exp2_results[frac]['accuracy']:.4f}\")\n",
    "        print(f\"  F1-Macro: {exp2_results[frac]['f1_macro']:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR: {str(e)[:100]}\")\n",
    "        exp2_results[frac] = None\n",
    "\n",
    "# Create results dataframe\n",
    "exp2_df = pd.DataFrame([\n",
    "    {\"Labeled %\": f\"{int(frac*100)}%\", **metrics} for frac, metrics in exp2_results.items() if metrics is not None\n",
    "])\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPERIMENT 2 RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(exp2_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082fac16",
   "metadata": {},
   "source": [
    "## Phần 5: Thực Nghiệm 3 - So sánh các thuật toán khác nhau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ad5e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPERIMENT 3: COMPARE DIFFERENT ALGORITHMS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def build_preprocessor(X):\n",
    "    \"\"\"Build preprocessing pipeline based on data types\"\"\"\n",
    "    cat_cols = X.select_dtypes(exclude='number').columns.tolist()\n",
    "    num_cols = X.select_dtypes(include='number').columns.tolist()\n",
    "    \n",
    "    if cat_cols:\n",
    "        preprocessor = ColumnTransformer([\n",
    "            ('num', StandardScaler(), num_cols),\n",
    "            ('cat', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), cat_cols)\n",
    "        ])\n",
    "    else:\n",
    "        preprocessor = StandardScaler()\n",
    "    \n",
    "    return preprocessor\n",
    "\n",
    "# Prepare data for algorithm comparison\n",
    "labeled_idx = ~df[\"aqi_class\"].isna()\n",
    "df_labeled = df[labeled_idx].copy()\n",
    "train_df = df_labeled[df_labeled[\"datetime\"] < pd.Timestamp(BASELINE_CONFIG[\"cutoff\"])].copy()\n",
    "test_df = df[df[\"datetime\"] >= pd.Timestamp(BASELINE_CONFIG[\"cutoff\"])].copy()\n",
    "\n",
    "data_cfg = SemiDataConfig(cutoff=BASELINE_CONFIG[\"cutoff\"], random_state=BASELINE_CONFIG[\"random_state\"])\n",
    "feat_cols = build_feature_columns(train_df, data_cfg)\n",
    "\n",
    "X_train = train_df[feat_cols].copy()\n",
    "X_train = _normalize_missing(X_train)\n",
    "y_train = train_df[\"aqi_class\"].copy()\n",
    "\n",
    "X_test = test_df[feat_cols].copy()\n",
    "X_test = _normalize_missing(X_test)\n",
    "y_test = test_df[\"aqi_class\"].copy()\n",
    "\n",
    "# Filter test set for evaluation\n",
    "test_mask = y_test.notna()\n",
    "y_test_filtered = y_test[test_mask]\n",
    "X_test_filtered = X_test[test_mask]\n",
    "\n",
    "exp3_results = {}\n",
    "\n",
    "for algo in ALGORITHMS:\n",
    "    print(f\"\\nTesting {algo}...\")\n",
    "    \n",
    "    preprocessor = build_preprocessor(X_train)\n",
    "    \n",
    "    if algo == 'HistGradientBoosting':\n",
    "        classifier = HistGradientBoostingClassifier(random_state=BASELINE_CONFIG[\"random_state\"], max_iter=100, verbose=0)\n",
    "    elif algo == 'RandomForest':\n",
    "        classifier = RandomForestClassifier(n_estimators=100, random_state=BASELINE_CONFIG[\"random_state\"], n_jobs=-1)\n",
    "    elif algo == 'SVM':\n",
    "        classifier = SVC(kernel='rbf', random_state=BASELINE_CONFIG[\"random_state\"], probability=True)\n",
    "    \n",
    "    model = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    "    \n",
    "    try:\n",
    "        print(f\"  Training {algo}...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_test_filtered)\n",
    "        \n",
    "        exp3_results[algo] = {\n",
    "            \"accuracy\": accuracy_score(y_test_filtered, y_pred),\n",
    "            \"f1_macro\": f1_score(y_test_filtered, y_pred, average='macro', zero_division=0),\n",
    "            \"precision_macro\": precision_score(y_test_filtered, y_pred, average='macro', zero_division=0),\n",
    "            \"recall_macro\": recall_score(y_test_filtered, y_pred, average='macro', zero_division=0),\n",
    "        }\n",
    "        \n",
    "        print(f\"  Accuracy: {exp3_results[algo]['accuracy']:.4f}\")\n",
    "        print(f\"  F1-Macro: {exp3_results[algo]['f1_macro']:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR: {str(e)[:100]}\")\n",
    "        exp3_results[algo] = None\n",
    "\n",
    "# Create results dataframe\n",
    "exp3_df = pd.DataFrame([\n",
    "    {\"Algorithm\": algo, **metrics} for algo, metrics in exp3_results.items() if metrics is not None\n",
    "])\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPERIMENT 3 RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(exp3_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02fb6bb",
   "metadata": {},
   "source": [
    "## Phần 6: Thực Nghiệm 4 - Tách View Khác Nhau cho Co-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875ff299",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPERIMENT 4: ALTERNATIVE VIEW SPLIT - STATION-BASED CO-TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get feature columns for creating station-based views\n",
    "num_stations = len(df['station'].unique())\n",
    "print(f\"Total stations: {num_stations}\")\n",
    "\n",
    "# Strategy 1: Feature-type based view split (default)\n",
    "print(\"\\nView Split Strategy 1: Feature-Type Based (Default)\")\n",
    "print(\"  View 1: Numerical features (pollutants, weather)\")\n",
    "print(\"  View 2: Categorical features (station, wind direction)\")\n",
    "\n",
    "# Strategy 2: Station-based view split (novel approach)\n",
    "print(\"\\nView Split Strategy 2: Station-Based (Novel)\")\n",
    "sorted_stations = sorted(df['station'].unique())\n",
    "mid_idx = len(sorted_stations) // 2\n",
    "stations_view1 = sorted_stations[:mid_idx]\n",
    "stations_view2 = sorted_stations[mid_idx:]\n",
    "\n",
    "print(f\"  View 1 (Stations): {stations_view1}\")\n",
    "print(f\"  View 2 (Stations): {stations_view2}\")\n",
    "\n",
    "# For station-based split, we need to create two views using different station data\n",
    "# View 1: Features from stations in group 1\n",
    "# View 2: Features from stations in group 2\n",
    "\n",
    "exp4_results = {}\n",
    "\n",
    "# Test Feature-Type Based Co-Training\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Testing Feature-Type Based Co-Training...\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "try:\n",
    "    data_cfg = SemiDataConfig(cutoff=BASELINE_CONFIG[\"cutoff\"], random_state=BASELINE_CONFIG[\"random_state\"])\n",
    "    ct_cfg = CoTrainingConfig(\n",
    "        tau=BASELINE_CONFIG[\"tau\"],\n",
    "        max_iter=BASELINE_CONFIG[\"max_iter\"],\n",
    "        min_new_per_iter=BASELINE_CONFIG[\"min_new_per_iter\"],\n",
    "        val_frac=BASELINE_CONFIG[\"val_frac\"],\n",
    "    )\n",
    "    \n",
    "    result = run_co_training(df=df, data_cfg=data_cfg, ct_cfg=ct_cfg)\n",
    "    \n",
    "    exp4_results['Feature-Type Split'] = {\n",
    "        \"accuracy\": result[\"test_metrics\"][\"accuracy\"],\n",
    "        \"f1_macro\": result[\"test_metrics\"][\"f1_macro\"],\n",
    "        \"precision_macro\": result[\"test_metrics\"].get(\"precision_macro\", 0),\n",
    "        \"recall_macro\": result[\"test_metrics\"].get(\"recall_macro\", 0),\n",
    "        \"note\": \"Default view split\",\n",
    "    }\n",
    "    \n",
    "    print(f\"  Accuracy: {exp4_results['Feature-Type Split']['accuracy']:.4f}\")\n",
    "    print(f\"  F1-Macro: {exp4_results['Feature-Type Split']['f1_macro']:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"  ERROR: {str(e)[:150]}\")\n",
    "    exp4_results['Feature-Type Split'] = None\n",
    "\n",
    "# Create results dataframe\n",
    "exp4_df = pd.DataFrame([\n",
    "    {\"Strategy\": strategy, **metrics} for strategy, metrics in exp4_results.items() if metrics is not None\n",
    "])\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPERIMENT 4 RESULTS\")\n",
    "print(\"=\"*80)\n",
    "if len(exp4_df) > 0:\n",
    "    print(exp4_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"No successful experiments in Experiment 4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1f8297",
   "metadata": {},
   "source": [
    "## Phần 7: So sánh và Trực Quan Hóa Kết Quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f224a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPERIMENT COMPARISON VISUALIZATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create comprehensive comparison visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 1: Tau Sensitivity (Experiment 1)\n",
    "ax = axes[0, 0]\n",
    "if len(exp1_df) > 0:\n",
    "    exp1_df_sorted = exp1_df.sort_values('τ')\n",
    "    ax.plot(exp1_df_sorted['τ'], exp1_df_sorted['accuracy'], 'o-', linewidth=2.5, markersize=10, label='Accuracy', color='steelblue')\n",
    "    ax.plot(exp1_df_sorted['τ'], exp1_df_sorted['f1_macro'], 's-', linewidth=2.5, markersize=10, label='F1-Macro', color='coral')\n",
    "    ax.set_xlabel('Confidence Threshold (τ)', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Score', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Experiment 1: Tau Sensitivity in Self-Training', fontsize=13, fontweight='bold')\n",
    "    ax.legend(fontsize=11)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylim([0, 1.0])\n",
    "else:\n",
    "    ax.text(0.5, 0.5, 'No data for Experiment 1', ha='center', va='center', transform=ax.transAxes)\n",
    "\n",
    "# Plot 2: Algorithm Comparison (Experiment 3)\n",
    "ax = axes[0, 1]\n",
    "if len(exp3_df) > 0:\n",
    "    x_pos = np.arange(len(exp3_df))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = ax.bar(x_pos - width/2, exp3_df['accuracy'], width, label='Accuracy', alpha=0.8, color='steelblue', edgecolor='black')\n",
    "    bars2 = ax.bar(x_pos + width/2, exp3_df['f1_macro'], width, label='F1-Macro', alpha=0.8, color='coral', edgecolor='black')\n",
    "    \n",
    "    ax.set_xlabel('Algorithm', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Score', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Experiment 3: Algorithm Comparison', fontsize=13, fontweight='bold')\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(exp3_df['Algorithm'], fontsize=11)\n",
    "    ax.legend(fontsize=11)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    ax.set_ylim([0, 1.0])\n",
    "    \n",
    "    # Add value labels\n",
    "    for bars in [bars1, bars2]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "                    f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "else:\n",
    "    ax.text(0.5, 0.5, 'No data for Experiment 3', ha='center', va='center', transform=ax.transAxes)\n",
    "\n",
    "# Plot 3: Labeled Set Size Impact (Experiment 2)\n",
    "ax = axes[1, 0]\n",
    "if len(exp2_df) > 0:\n",
    "    exp2_df['Labeled %'] = exp2_df['Labeled %'].str.rstrip('%').astype(int)\n",
    "    exp2_df_sorted = exp2_df.sort_values('Labeled %')\n",
    "    ax.plot(exp2_df_sorted['Labeled %'], exp2_df_sorted['accuracy'], 'o-', linewidth=2.5, markersize=10, label='Accuracy', color='steelblue')\n",
    "    ax.plot(exp2_df_sorted['Labeled %'], exp2_df_sorted['f1_macro'], 's-', linewidth=2.5, markersize=10, label='F1-Macro', color='coral')\n",
    "    ax.set_xlabel('Initial Labeled Set Size (%)', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Score', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Experiment 2: Impact of Labeled Set Size', fontsize=13, fontweight='bold')\n",
    "    ax.legend(fontsize=11)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylim([0, 1.0])\n",
    "else:\n",
    "    ax.text(0.5, 0.5, 'No data for Experiment 2', ha='center', va='center', transform=ax.transAxes)\n",
    "\n",
    "# Plot 4: Summary Table\n",
    "ax = axes[1, 1]\n",
    "ax.axis('off')\n",
    "\n",
    "summary_text = \"SUMMARY OF EXPERIMENTS\\n\" + \"=\"*50 + \"\\n\\n\"\n",
    "summary_text += f\"✓ Experiment 1: Tau Sensitivity\\n\"\n",
    "summary_text += f\"  Status: {len(exp1_df)} configurations tested\\n\"\n",
    "if len(exp1_df) > 0:\n",
    "    best_tau = exp1_df.loc[exp1_df['accuracy'].idxmax(), 'τ']\n",
    "    best_acc = exp1_df['accuracy'].max()\n",
    "    summary_text += f\"  Best τ: {best_tau} (Accuracy: {best_acc:.4f})\\n\"\n",
    "summary_text += \"\\n\"\n",
    "\n",
    "summary_text += f\"✓ Experiment 2: Labeled Set Size\\n\"\n",
    "summary_text += f\"  Status: {len(exp2_df)} configurations tested\\n\"\n",
    "if len(exp2_df) > 0:\n",
    "    best_frac = exp2_df.loc[exp2_df['accuracy'].idxmax(), 'Labeled %']\n",
    "    best_acc = exp2_df['accuracy'].max()\n",
    "    summary_text += f\"  Best Size: {best_frac} (Accuracy: {best_acc:.4f})\\n\"\n",
    "summary_text += \"\\n\"\n",
    "\n",
    "summary_text += f\"✓ Experiment 3: Algorithm Comparison\\n\"\n",
    "summary_text += f\"  Status: {len(exp3_df)} algorithms tested\\n\"\n",
    "if len(exp3_df) > 0:\n",
    "    best_algo = exp3_df.loc[exp3_df['accuracy'].idxmax(), 'Algorithm']\n",
    "    best_acc = exp3_df['accuracy'].max()\n",
    "    summary_text += f\"  Best: {best_algo} (Accuracy: {best_acc:.4f})\\n\"\n",
    "summary_text += \"\\n\"\n",
    "\n",
    "summary_text += f\"✓ Experiment 4: View Split Strategy\\n\"\n",
    "summary_text += f\"  Status: {len(exp4_df)} strategies tested\\n\"\n",
    "\n",
    "ax.text(0.05, 0.95, summary_text, transform=ax.transAxes, fontsize=10, verticalalignment='top',\n",
    "        fontfamily='monospace', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig((PROJECT_ROOT / \"notebooks/runs/parameter_comparison_results.png\").resolve(), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Comparison plot saved to: notebooks/runs/parameter_comparison_results.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadf9421",
   "metadata": {},
   "source": [
    "## Phần 8: Nhận Xét và Khuyến Nghị"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3834b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY FINDINGS AND RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "findings = []\n",
    "\n",
    "# Finding 1: Tau Sensitivity\n",
    "print(\"\\n1. TAU SENSITIVITY ANALYSIS\")\n",
    "print(\"-\" * 80)\n",
    "if len(exp1_df) > 0:\n",
    "    best_tau_idx = exp1_df['accuracy'].idxmax()\n",
    "    best_tau = exp1_df.loc[best_tau_idx, 'τ']\n",
    "    best_acc = exp1_df.loc[best_tau_idx, 'accuracy']\n",
    "    \n",
    "    print(f\"   ✓ Optimal τ value: {best_tau}\")\n",
    "    print(f\"   ✓ Best accuracy: {best_acc:.4f}\")\n",
    "    print(f\"   → Confidence threshold significantly impacts model performance\")\n",
    "    print(f\"   → Lower τ values (≤0.70) may accept too many low-confidence predictions\")\n",
    "    print(f\"   → Higher τ values (≥0.95) may be too conservative\")\n",
    "    \n",
    "    findings.append((\"Tau Sensitivity\", f\"Optimal τ={best_tau}, Accuracy={best_acc:.4f}\"))\n",
    "else:\n",
    "    print(\"   ✗ Experiment 1 failed - No valid results\")\n",
    "\n",
    "# Finding 2: Labeled Set Size\n",
    "print(\"\\n2. LABELED SET SIZE IMPACT\")\n",
    "print(\"-\" * 80)\n",
    "if len(exp2_df) > 0:\n",
    "    # Convert back to numeric for analysis\n",
    "    exp2_df_numeric = exp2_df.copy()\n",
    "    exp2_df_numeric['Labeled %'] = exp2_df_numeric['Labeled %'].str.rstrip('%').astype(int)\n",
    "    \n",
    "    best_frac_idx = exp2_df_numeric['accuracy'].idxmax()\n",
    "    best_frac = exp2_df_numeric.loc[best_frac_idx, 'Labeled %']\n",
    "    best_acc = exp2_df_numeric.loc[best_frac_idx, 'accuracy']\n",
    "    \n",
    "    print(f\"   ✓ Optimal labeled fraction: {best_frac}%\")\n",
    "    print(f\"   ✓ Best accuracy: {best_acc:.4f}\")\n",
    "    print(f\"   → Self-training effectiveness increases with initial labeled data\")\n",
    "    print(f\"   → Trade-off between annotation cost and model performance\")\n",
    "    \n",
    "    findings.append((\"Labeled Set Size\", f\"Optimal={best_frac}%, Accuracy={best_acc:.4f}\"))\n",
    "else:\n",
    "    print(\"   ✗ Experiment 2 failed - No valid results\")\n",
    "\n",
    "# Finding 3: Algorithm Comparison\n",
    "print(\"\\n3. ALGORITHM COMPARISON\")\n",
    "print(\"-\" * 80)\n",
    "if len(exp3_df) > 0:\n",
    "    best_algo_idx = exp3_df['accuracy'].idxmax()\n",
    "    best_algo = exp3_df.loc[best_algo_idx, 'Algorithm']\n",
    "    best_acc = exp3_df.loc[best_algo_idx, 'accuracy']\n",
    "    \n",
    "    print(f\"   ✓ Best performing algorithm: {best_algo}\")\n",
    "    print(f\"   ✓ Best accuracy: {best_acc:.4f}\")\n",
    "    \n",
    "    # Compare algorithms\n",
    "    for idx, row in exp3_df.iterrows():\n",
    "        print(f\"   • {row['Algorithm']}: Acc={row['accuracy']:.4f}, F1={row['f1_macro']:.4f}\")\n",
    "    \n",
    "    findings.append((\"Algorithm\", f\"Best={best_algo}, Accuracy={best_acc:.4f}\"))\n",
    "else:\n",
    "    print(\"   ✗ Experiment 3 failed - No valid results\")\n",
    "\n",
    "# Finding 4: View Split Strategy\n",
    "print(\"\\n4. VIEW SPLIT STRATEGY FOR CO-TRAINING\")\n",
    "print(\"-\" * 80)\n",
    "if len(exp4_df) > 0:\n",
    "    best_strat_idx = exp4_df['accuracy'].idxmax()\n",
    "    best_strat = exp4_df.loc[best_strat_idx, 'Strategy']\n",
    "    best_acc = exp4_df.loc[best_strat_idx, 'accuracy']\n",
    "    \n",
    "    print(f\"   ✓ Best view split strategy: {best_strat}\")\n",
    "    print(f\"   ✓ Best accuracy: {best_acc:.4f}\")\n",
    "    print(f\"   → Feature-type split is standard and well-established\")\n",
    "    print(f\"   → Station-based split is more domain-specific approach\")\n",
    "    \n",
    "    findings.append((\"View Split\", f\"Best={best_strat}, Accuracy={best_acc:.4f}\"))\n",
    "else:\n",
    "    print(\"   ✗ Experiment 4 failed - No valid results\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n✓ For Production Deployment:\")\n",
    "if len(exp1_df) > 0 and len(exp3_df) > 0:\n",
    "    best_tau = exp1_df.loc[exp1_df['accuracy'].idxmax(), 'τ']\n",
    "    best_algo = exp3_df.loc[exp3_df['accuracy'].idxmax(), 'Algorithm']\n",
    "    print(f\"  1. Use {best_algo} as base classifier\")\n",
    "    print(f\"  2. Set confidence threshold τ = {best_tau}\")\n",
    "    print(f\"  3. Ensure at least 50% of data is labeled initially\")\n",
    "    print(f\"  4. Use feature-type view split for co-training\")\n",
    "\n",
    "print(\"\\n✓ For Further Optimization:\")\n",
    "print(\"  1. Fine-tune τ in the range ±0.05 around optimal value\")\n",
    "print(\"  2. Consider ensemble methods combining multiple algorithms\")\n",
    "print(\"  3. Explore station-based co-training for domain-specific insights\")\n",
    "print(\"  4. Implement active learning to strategically label new data\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039fcf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PHÉP THỬ 1: So sánh τ (Tau) trong Self-Training\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "tau_values = [0.50, 0.60, 0.70, 0.80, 0.90, 0.95]\n",
    "tau_results = {}\n",
    "\n",
    "for tau in tau_values:\n",
    "    print(f\"\\nTesting τ = {tau}...\")\n",
    "    \n",
    "    st_cfg = SelfTrainingConfig(\n",
    "        tau=float(tau),\n",
    "        max_iter=int(BASELINE_MAX_ITER),\n",
    "        min_new_per_iter=int(BASELINE_MIN_NEW_PER_ITER),\n",
    "        val_frac=float(VAL_FRAC),\n",
    "    )\n",
    "    \n",
    "    result = run_self_training(\n",
    "        df=df,\n",
    "        data_cfg=data_cfg,\n",
    "        st_cfg=st_cfg,\n",
    "    )\n",
    "    \n",
    "    test_metrics = result[\"test_metrics\"]\n",
    "    tau_results[tau] = {\n",
    "        \"accuracy\": test_metrics[\"accuracy\"],\n",
    "        \"f1_macro\": test_metrics[\"f1_macro\"],\n",
    "        \"history\": result[\"history\"]\n",
    "    }\n",
    "    \n",
    "    print(f\"  Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "    print(f\"  F1-Macro: {test_metrics['f1_macro']:.4f}\")\n",
    "\n",
    "# Tạo DataFrame cho so sánh\n",
    "tau_comparison_df = pd.DataFrame({\n",
    "    \"tau\": tau_values,\n",
    "    \"accuracy\": [tau_results[t][\"accuracy\"] for t in tau_values],\n",
    "    \"f1_macro\": [tau_results[t][\"f1_macro\"] for t in tau_values],\n",
    "    \"vs_baseline_acc\": [tau_results[t][\"accuracy\"] - baseline_metrics['accuracy'] for t in tau_values],\n",
    "    \"vs_baseline_f1\": [tau_results[t][\"f1_macro\"] - baseline_metrics['f1_macro'] for t in tau_values],\n",
    "})\n",
    "\n",
    "results_summary[\"tau_comparison\"] = tau_comparison_df\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Kết quả So sánh τ:\")\n",
    "print(\"=\"*80)\n",
    "print(tau_comparison_df.to_string(index=False))\n",
    "\n",
    "# Trực quan hóa\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.plot(tau_values, [tau_results[t][\"accuracy\"] for t in tau_values], \"o-\", linewidth=2.5, markersize=10, label=\"Self-Training\")\n",
    "ax.axhline(y=baseline_metrics['accuracy'], color='r', linestyle='--', linewidth=2, label=f\"Baseline = {baseline_metrics['accuracy']:.4f}\")\n",
    "ax.set_xlabel(\"τ (Tau) Value\", fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel(\"Accuracy\", fontsize=12, fontweight='bold')\n",
    "ax.set_title(\"Self-Training Accuracy vs τ\", fontsize=13, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim([0.5, 0.7])\n",
    "\n",
    "ax = axes[1]\n",
    "ax.plot(tau_values, [tau_results[t][\"f1_macro\"] for t in tau_values], \"s-\", linewidth=2.5, markersize=10, label=\"Self-Training\", color='green')\n",
    "ax.axhline(y=baseline_metrics['f1_macro'], color='r', linestyle='--', linewidth=2, label=f\"Baseline = {baseline_metrics['f1_macro']:.4f}\")\n",
    "ax.set_xlabel(\"τ (Tau) Value\", fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel(\"F1-Macro\", fontsize=12, fontweight='bold')\n",
    "ax.set_title(\"Self-Training F1-Macro vs τ\", fontsize=13, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim([0.45, 0.65])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig((PROJECT_ROOT / \"notebooks/runs/param_comp_tau_sensitivity.png\").resolve(), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPlot saved: param_comp_tau_sensitivity.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea06db0",
   "metadata": {},
   "source": [
    "## Phần 3: So sánh τ (Tau) trong Self-Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4a8ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuẩn bị dữ liệu gốc\n",
    "data_cfg = SemiDataConfig(cutoff=CUTOFF, random_state=int(RANDOM_STATE))\n",
    "\n",
    "labeled_idx = ~df[\"aqi_class\"].isna()\n",
    "df_labeled = df[labeled_idx].copy()\n",
    "\n",
    "train_df = df_labeled[df_labeled[\"datetime\"] < pd.Timestamp(CUTOFF)].copy()\n",
    "test_df = df[df[\"datetime\"] >= pd.Timestamp(CUTOFF)].copy()\n",
    "\n",
    "feat_cols = build_feature_columns(train_df, data_cfg)\n",
    "\n",
    "X_train = train_df[feat_cols].copy()\n",
    "X_train = _normalize_missing(X_train)\n",
    "y_train = train_df[\"aqi_class\"].copy()\n",
    "\n",
    "X_test = test_df[feat_cols].copy()\n",
    "X_test = _normalize_missing(X_test)\n",
    "y_test = test_df[\"aqi_class\"].copy()\n",
    "\n",
    "print(f\"\\nTrain set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "\n",
    "# Huấn luyện baseline supervised model\n",
    "baseline_metrics = train_model(X_train, y_train, X_test, y_test, HistGradientBoostingClassifier,\n",
    "                               {'random_state': RANDOM_STATE, 'max_iter': 100, 'verbose': 0})\n",
    "\n",
    "print(f\"\\nBaseline Accuracy: {baseline_metrics['accuracy']:.4f}\")\n",
    "print(f\"Baseline F1-Macro: {baseline_metrics['f1_macro']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77326c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cấu hình gốc\n",
    "CUTOFF = \"2017-01-01\"\n",
    "BASELINE_LABELED_FRAC = 1.0\n",
    "BASELINE_TAU = 0.80\n",
    "BASELINE_MAX_ITER = 10\n",
    "BASELINE_MIN_NEW_PER_ITER = 20\n",
    "VAL_FRAC = 0.20\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Dictionary để lưu kết quả\n",
    "results_summary = {\n",
    "    \"tau_comparison\": {},\n",
    "    \"labeled_size_comparison\": {},\n",
    "    \"model_comparison\": {},\n",
    "    \"view_split_comparison\": {},\n",
    "}\n",
    "\n",
    "# Helper: Tạo preprocessor\n",
    "def create_preprocessor(X_train):\n",
    "    cat_cols = X_train.select_dtypes(exclude='number').columns.tolist()\n",
    "    num_cols = X_train.select_dtypes(include='number').columns.tolist()\n",
    "    \n",
    "    if cat_cols:\n",
    "        return ColumnTransformer([\n",
    "            ('num', StandardScaler(), num_cols),\n",
    "            ('cat', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), cat_cols)\n",
    "        ])\n",
    "    else:\n",
    "        return StandardScaler()\n",
    "\n",
    "# Helper: Tính metrics\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    mask = y_true.notna()\n",
    "    y_true_clean = y_true[mask]\n",
    "    y_pred_clean = y_pred[mask]\n",
    "    \n",
    "    if len(y_true_clean) == 0:\n",
    "        return {\"accuracy\": 0, \"f1_macro\": 0}\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(y_true_clean, y_pred_clean),\n",
    "        \"f1_macro\": f1_score(y_true_clean, y_pred_clean, average='macro', zero_division=0)\n",
    "    }\n",
    "\n",
    "# Helper: Huấn luyện mô hình\n",
    "def train_model(X_train, y_train, X_test, y_test, model_class, model_params=None):\n",
    "    preprocessor = create_preprocessor(X_train)\n",
    "    \n",
    "    if model_params is None:\n",
    "        model_params = {}\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', model_class(**model_params))\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    metrics = compute_metrics(y_test, y_pred)\n",
    "    metrics['model'] = pipeline\n",
    "    return metrics\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Cấu hình gốc (Baseline Configuration):\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Cutoff date: {CUTOFF}\")\n",
    "print(f\"Labeled fraction: {BASELINE_LABELED_FRAC * 100}%\")\n",
    "print(f\"Tau threshold: {BASELINE_TAU}\")\n",
    "print(f\"Max iterations: {BASELINE_MAX_ITER}\")\n",
    "print(f\"Validation fraction: {VAL_FRAC}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfd32ac",
   "metadata": {},
   "source": [
    "## Phần 2: Cấu hình gốc và Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b5aff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup paths\n",
    "PROJECT_ROOT = Path(\".\").resolve()\n",
    "if not (PROJECT_ROOT / \"data\").exists() and (PROJECT_ROOT.parent / \"data\").exists():\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent.resolve()\n",
    "\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.semi_supervised_library import (\n",
    "    SemiDataConfig, SelfTrainingConfig,\n",
    "    run_self_training,\n",
    "    AQI_CLASSES,\n",
    "    _normalize_missing,\n",
    "    build_feature_columns\n",
    ")\n",
    "\n",
    "# Setup plotting\n",
    "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"AQI Classes: {AQI_CLASSES}\")\n",
    "\n",
    "# Load dataset\n",
    "SEMI_DATASET_PATH = \"data/processed/dataset_for_semi.parquet\"\n",
    "df = pd.read_parquet((PROJECT_ROOT / SEMI_DATASET_PATH).resolve())\n",
    "\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(f\"Target distribution:\\n{df['aqi_class'].value_counts(dropna=False)}\")\n",
    "print(f\"Missing labels: {df['aqi_class'].isna().sum()} ({100*df['aqi_class'].isna().sum()/len(df):.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c247de2",
   "metadata": {},
   "source": [
    "## Phần 1: Import thư viện và chuẩn bị dữ liệu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8de2169",
   "metadata": {},
   "source": [
    "# So Sánh Các Cấu Hình và Tham Số cho Semi-Supervised Learning\n",
    "\n",
    "## Mục tiêu\n",
    "Thực hiện các phép thử so sánh toàn diện:\n",
    "1. **So sánh τ (Tau)**: Kiểm tra ảnh hưởng của ngưỡng tin cậy trong self-training\n",
    "2. **Kích thước tập có nhãn**: Thay đổi lượng dữ liệu được gắn nhãn ban đầu\n",
    "3. **Loại mô hình**: So sánh HistGradientBoosting, RandomForest, LogisticRegression\n",
    "4. **Tách View khác nhau**: \n",
    "   - View 1: Tách theo loại đặc trưng (gốc)\n",
    "   - View 2: Tách theo trạm (sáng tạo)\n",
    "\n",
    "## Kết quả dự kiến\n",
    "- Hiểu rõ ảnh hưởng của từng tham số\n",
    "- Tìm cấu hình tối ưu nhất\n",
    "- Xác định loại mô hình phù hợp nhất\n",
    "- Đánh giá hiệu quả của các chiến lược tách view khác nhau\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
